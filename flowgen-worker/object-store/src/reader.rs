use super::config::{DEFAULT_AVRO_EXTENSION, DEFAULT_CSV_EXTENSION, DEFAULT_JSON_EXTENSION};
use bytes::Bytes;
use flowgen_core::buffer::{ContentType, FromReader};
use flowgen_core::cache::Cache;
use flowgen_core::event::{generate_subject, Event, EventBuilder, SubjectSuffix, DEFAULT_LOG_MESSAGE};
use flowgen_core::{client::Client, event::EventData};
use object_store::GetResultPayload;
use std::io::BufReader;
use std::sync::Arc;
use tokio::sync::{
    broadcast::{Receiver, Sender},
    Mutex,
};
use tracing::{event, Level};

/// Default subject prefix for logging messages.
const DEFAULT_MESSAGE_SUBJECT: &str = "object_store.reader.in";
/// Default batch size for files.
const DEFAULT_BATCH_SIZE: usize = 1000;
/// Default files have headers.
const DEFAULT_HAS_HEADER: bool = true;

#[derive(thiserror::Error, Debug)]
#[non_exhaustive]
pub enum Error {
    #[error(transparent)]
    IO(#[from] std::io::Error),
    #[error(transparent)]
    Arrow(#[from] arrow::error::ArrowError),
    #[error(transparent)]
    Avro(#[from] apache_avro::Error),
    #[error(transparent)]
    SerdeJson(#[from] serde_json::Error),
    #[error(transparent)]
    ObjectStore(#[from] object_store::Error),
    #[error(transparent)]
    ObjectStoreClient(#[from] super::client::Error),
    #[error(transparent)]
    Event(#[from] flowgen_core::event::Error),
    #[error(transparent)]
    SendMessage(#[from] tokio::sync::broadcast::error::SendError<Event>),
    #[error(transparent)]
    ConfigRender(#[from] flowgen_core::config::Error),
    #[error("missing required attribute: {}", _0)]
    MissingRequiredAttribute(String),
    #[error("could not initialize object store context")]
    NoObjectStoreContext(),
    #[error("could not retrieve file extension")]
    NoFileExtension(),
    #[error("cache errors")]
    Cache(),
}

/// Handles processing of individual events by writing them to object storage.
struct EventHandler<T: Cache> {
    /// Writer configuration settings.
    config: Arc<super::config::Reader>,
    /// Object store client for writing data.
    client: Arc<Mutex<super::client::Client>>,
    /// Channel sender for processed events
    tx: Sender<Event>,
    /// Current task identifier for event filtering.
    current_task_id: usize,
    /// Cache object for storing / retriving data.
    cache: Arc<T>,
}

impl<T: Cache> EventHandler<T> {
    /// Processes an event and writes it to the configured object store.
    async fn handle(self, _: Event) -> Result<(), Error> {
        let mut client_guard = self.client.lock().await;
        let context = client_guard
            .context
            .as_mut()
            .ok_or_else(Error::NoObjectStoreContext)?;

        let result = context.object_store.get(&context.path).await?;

        let extension = result
            .meta
            .location
            .extension()
            .ok_or_else(Error::NoFileExtension)?;

        match result.payload {
            GetResultPayload::File(file, _) => {
                let content_type = match extension {
                    DEFAULT_JSON_EXTENSION => ContentType::Json,
                    DEFAULT_CSV_EXTENSION => {
                        let batch_size = self.config.batch_size.unwrap_or(DEFAULT_BATCH_SIZE);
                        let has_header = self.config.has_header.unwrap_or(DEFAULT_HAS_HEADER);

                        ContentType::Csv {
                            batch_size,
                            has_header,
                        }
                    }
                    DEFAULT_AVRO_EXTENSION => ContentType::Avro,
                    _ => {
                        event!(Level::WARN, "Unsupported file extension: {}", extension);
                        return Ok(());
                    }
                };

                let reader = BufReader::new(file);
                let event_data_list = EventData::from_reader(reader, content_type.clone())?;

                if let ContentType::Csv { .. } = content_type {
                    if let Some(cache_options) = &self.config.cache_options {
                        if let Some(insert_key) = &cache_options.insert_key {
                            if let Some(EventData::ArrowRecordBatch(batch)) =
                                event_data_list.first()
                            {
                                let schema_bytes = Bytes::from(batch.schema().to_string());
                                self.cache
                                    .put(insert_key.as_str(), schema_bytes)
                                    .await
                                    .map_err(|_| Error::Cache())?;
                            }
                        }
                    }
                }

                for event_data in event_data_list {
                    // Generate event subject.
                    let subject = generate_subject(
                        self.config.label.as_deref(),
                        DEFAULT_MESSAGE_SUBJECT,
                        SubjectSuffix::Timestamp,
                    );

                    // Build and send event.
                    let e = EventBuilder::new()
                        .subject(subject)
                        .data(event_data)
                        .current_task_id(self.current_task_id)
                        .build()?;

                    event!(Level::INFO, "{}: {}", DEFAULT_LOG_MESSAGE, e.subject);
                    self.tx.send(e)?;
                }
            }
            GetResultPayload::Stream(_pin) => todo!(),
        }
        Ok(())
    }
}

/// Object store reader that processes events from a broadcast receiver.
pub struct Reader<T: Cache> {
    /// Reader configuration settings.
    config: Arc<super::config::Reader>,
    /// Broadcast receiver for incoming events.
    rx: Receiver<Event>,
    /// Channel sender for processed events
    tx: Sender<Event>,
    /// Current task identifier for event filtering.
    current_task_id: usize,
    /// Cache object for storing / retriving data.
    cache: Arc<T>,
}

impl<T: Cache> flowgen_core::task::runner::Runner for Reader<T> {
    type Error = Error;

    async fn run(mut self) -> Result<(), Self::Error> {
        // Build object store client with conditional configuration
        let mut client_builder = super::client::ClientBuilder::new().path(self.config.path.clone());

        if let Some(options) = &self.config.client_options {
            client_builder = client_builder.options(options.clone());
        }
        if let Some(credentials) = &self.config.credentials {
            client_builder = client_builder.credentials(credentials.to_path_buf());
        }

        let client = Arc::new(Mutex::new(client_builder.build()?.connect().await?));

        // Process incoming events, filtering by task ID.
        while let Ok(event) = self.rx.recv().await {
            if event.current_task_id == Some(self.current_task_id - 1) {
                let client = Arc::clone(&client);
                let config = Arc::clone(&self.config);
                let cache = Arc::clone(&self.cache);
                let tx = self.tx.clone();
                let current_task_id = self.current_task_id;
                let event_handler = EventHandler {
                    client,
                    config,
                    tx,
                    current_task_id,
                    cache,
                };
                tokio::spawn(async move {
                    if let Err(err) = event_handler.handle(event).await {
                        event!(Level::ERROR, "{}", err);
                    }
                });
            }
        }
        Ok(())
    }
}

/// Builder pattern for constructing Writer instances.
#[derive(Default)]
pub struct ReaderBuilder<T: Cache> {
    /// Writer configuration settings.
    config: Option<Arc<super::config::Reader>>,
    /// Broadcast receiver for incoming events.
    rx: Option<Receiver<Event>>,
    /// Event channel sender
    tx: Option<Sender<Event>>,
    /// Current task identifier for event filtering.
    current_task_id: usize,
    /// Cache object for storing / retriving data.
    cache: Option<Arc<T>>,
}

impl<T: Cache> ReaderBuilder<T>
where
    T: Default,
{
    pub fn new() -> ReaderBuilder<T> {
        ReaderBuilder {
            ..Default::default()
        }
    }

    /// Sets the writer configuration.
    pub fn config(mut self, config: Arc<super::config::Reader>) -> Self {
        self.config = Some(config);
        self
    }

    /// Sets the event receiver.
    pub fn receiver(mut self, receiver: Receiver<Event>) -> Self {
        self.rx = Some(receiver);
        self
    }

    /// Sets the event sender.
    pub fn sender(mut self, sender: Sender<Event>) -> Self {
        self.tx = Some(sender);
        self
    }

    /// Sets the cache object.
    pub fn cache(mut self, cache: Arc<T>) -> Self {
        self.cache = Some(cache);
        self
    }

    /// Sets the current task identifier.
    pub fn current_task_id(mut self, current_task_id: usize) -> Self {
        self.current_task_id = current_task_id;
        self
    }

    /// Builds the Writer instance, validating required fields.
    pub async fn build(self) -> Result<Reader<T>, Error> {
        Ok(Reader {
            config: self
                .config
                .ok_or_else(|| Error::MissingRequiredAttribute("config".to_string()))?,
            rx: self
                .rx
                .ok_or_else(|| Error::MissingRequiredAttribute("receiver".to_string()))?,
            tx: self
                .tx
                .ok_or_else(|| Error::MissingRequiredAttribute("sender".to_string()))?,
            cache: self
                .cache
                .ok_or_else(|| Error::MissingRequiredAttribute("cache".to_string()))?,
            current_task_id: self.current_task_id,
        })
    }
}
